{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SCI6485 Introduction to Generative Artificial Intelligence\n",
        "\n",
        "##  STYLEGAN3\n",
        "\n",
        "\n",
        "**Harvard University**<br/>\n",
        "**Fall 2023**<br/>\n",
        "**Instructor:**  Sabrina Osmany<br/>\n",
        "**TA:**  Jiabin Wei<br/>\n",
        "\n",
        "**DISCLAIMER**: No public reproduction of this code is allowed without the explicit consent of their authors.\n",
        "\n",
        "<hr style=\"height:2pt\">\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "R7Z6AooI6an4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " This tutorial is heavily borrowed from this github [repo](https://github.com/derekphilipau/machinelearningforartists)."
      ],
      "metadata": {
        "id": "o6FRPYcEl5J4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba1NQzpO9iJ4"
      },
      "source": [
        "# Training custom data with StyleGAN\n",
        "\n",
        "In this tutorial, we only want to familiarize ourselves with running StyleGAN (in this case, the newest version) and seeing how training progresses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLqHshr2y-MO"
      },
      "source": [
        "## Verify Runtime is GPU\n",
        "\n",
        "In the menu, select Runtime -> Change Runtime Type and verify you are using the **GPU**.  Also select **High-RAM** if you are using Colab Pro.\n",
        "\n",
        "The `nvidia-smi` command below should **NOT** display *\"NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver.\"*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7JvPMLWy95f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9c55b6-2ea4-4b2d-8dd0-cf0372857e75"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUl3Rt0ryX7m"
      },
      "source": [
        "## Mount your Google Drive\n",
        "\n",
        "You will be storing the training models and progress images on your Google Drive.  This is very convenient for viewing progress, and if your Colab notebook is disconnected you will not lose your models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag2Bb1pPzthT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4987b6d-9aab-4927-a2ad-1a6b25567180"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIHuj2eEy13f"
      },
      "source": [
        "## Install Stylegan2-ada-pytorch Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8r0Ca7Hpo5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058c3af1-88a5-4a46-88cc-8b33ab53fe06"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Selected device: {device}')\n",
        "!pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected device: cpu\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting pyspng\n",
            "  Downloading pyspng-0.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.9/205.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imageio-ffmpeg==0.4.3\n",
            "  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyspng) (1.23.5)\n",
            "Installing collected packages: ninja, pyspng, imageio-ffmpeg\n",
            "  Attempting uninstall: imageio-ffmpeg\n",
            "    Found existing installation: imageio-ffmpeg 0.4.9\n",
            "    Uninstalling imageio-ffmpeg-0.4.9:\n",
            "      Successfully uninstalled imageio-ffmpeg-0.4.9\n",
            "Successfully installed imageio-ffmpeg-0.4.3 ninja-1.11.1 pyspng-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b94le1Kh_v1k"
      },
      "source": [
        "## Get the StyleGAN code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone StyleGan repo from github\n",
        "!git clone https://github.com/NVlabs/stylegan3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_iOs35I9AMV",
        "outputId": "00d1604a-1c24-4b2d-9929-bd8b39e5761f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 212 (delta 0), reused 1 (delta 0), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (212/212), 4.16 MiB | 9.05 MiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " create a dataset folder under your stylegan directory"
      ],
      "metadata": {
        "id": "x8s3riCV4f8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir /content/stylegan3/datasets"
      ],
      "metadata": {
        "id": "6I2ewrQ79D0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpk9vGb50lee"
      },
      "source": [
        "## Load a custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSNoTfiPcrNy"
      },
      "source": [
        "#######################################################\n",
        "#      unzip the custome dataset zip file to the 'datasets' folder under the 'stylegan3' directory\n",
        "#      you need to replace the path after 'unzip' with your zip file directory\n",
        "#######################################################\n",
        "\n",
        "# Custom datasets can be created from a folder containing images\n",
        "# unzip your custom data zip file to stylegan3 dataset directory\n",
        "!unzip /content/drive/MyDrive/MDE/SCI6485/StyleGan/custom_data/custom_data.zip -d /content/stylegan3/datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Anm9DkOccyMZ"
      },
      "source": [
        "# remove the \"__MACOSX\" directory from a Unix-based file system, typically found in ZIP or compressed archives created on macOS.\n",
        "!rm -rf /content/stylegan3/datasets/__MACOSX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBg2Zy06dkqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc68c35-84a2-45ba-de44-03683b0832c9"
      },
      "source": [
        "cd /content/stylegan3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9vyojRAvo8J",
        "outputId": "875741b5-11d0-49b4-c794-e954e5103c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_spectra.py   \u001b[0m\u001b[01;34mdnnlib\u001b[0m/          gen_images.py  LICENSE.txt   \u001b[01;34mtraining\u001b[0m/\n",
            "calc_metrics.py  Dockerfile       gen_video.py   \u001b[01;34mmetrics\u001b[0m/      train.py\n",
            "\u001b[01;34mdatasets\u001b[0m/        \u001b[01;34mdocs\u001b[0m/            \u001b[01;34mgui_utils\u001b[0m/     README.md     visualizer.py\n",
            "dataset_tool.py  environment.yml  legacy.py      \u001b[01;34mtorch_utils\u001b[0m/  \u001b[01;34mviz\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQfprRHj_-gH"
      },
      "source": [
        "## Prepare your custom dataset for use by StyleGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_szXOaO0WI00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e6a073-01e2-4aa0-93e3-7b30ef73f036"
      },
      "source": [
        "#######################################################\n",
        "#      set --source= as the directory your dataset folder\n",
        "#      set --dest= as the directory and the folder name of the new compressed zip file\n",
        "#######################################################\n",
        "\n",
        "# Datasets are stored as uncompressed ZIP archives containing uncompressed PNG files and a metadata file dataset.json for labels.\n",
        "# !python dataset_tool.py --source=./datasets/custom_data --dest=./datasets/customdataset.zip\n",
        "\n",
        "# you can also scale down the resolution of images here. You could use this line to check the explanation for the parameters: !python dataset_tool.py --help\n",
        "!python dataset_tool.py --source=./datasets/custom_data --dest=./datasets/customdataset.zip --resolution=128x128"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 4729/4729 [00:20<00:00, 232.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTo4K3m8AEzh"
      },
      "source": [
        "## Create Folders on Your Google Drive to Store Results\n",
        "\n",
        "If we accidentally close our browser or the Colab runtime disconnects, we will lose all of our training models and progress images.  Therefore we want to store the training data on our Google Drive.  The following cells will help you create a new folder on your Google Drive and then your training data will be stored in this path later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tja3AaYIHU9v"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/MDE/SCI6485/StyleGan/custom_data_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS14PMAY6SUW"
      },
      "source": [
        "If you get an error \"cannot create directory\", it's probably because the folder already exists on your Google Drive and you can ignore the error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpR6A_qBAo8m"
      },
      "source": [
        "## Train from Scratch\n",
        "\n",
        "This cell block will train StyleGAN from scratch.  Training from scratch is much slower than using *transfer learning* on a previously trained model.  However, the purpose of this tutorial is to a) try training for the first time and b) notice how the progress images develop over time."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want check the meaning of the parameters in the train.py, you could run this code\n",
        "!python train.py --help"
      ],
      "metadata": {
        "id": "yKfzAqUBjx3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################\n",
        "#      set --outdir= as the directory you want to store your training result\n",
        "#      set --data= as the compressed zip file generated by the dataset_tool.py from above\n",
        "#######################################################\n",
        "\n",
        "# train the model\n",
        "!python train.py --outdir=/content/drive/MyDrive/MDE/SCI6485/StyleGan/custom_data_result --cfg=stylegan3-t --data=./datasets/customdataset.zip  --gpus=1 --batch=32 --batch-gpu=4 --gamma=10.0 --mirror=1 --kimg=5000 --snap=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uyYy5KX_MKC",
        "outputId": "14a054b9-6ef5-42c6-fc92-f361cae6da30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 10.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./datasets/customdataset.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 4729,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 128,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 5000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 1,\n",
            "  \"network_snapshot_ticks\": 1,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/MDE/SCI6485/StyleGan/custom_data_result/00000-stylegan3-t-customdataset-gpus1-batch32-gamma10\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/MDE/SCI6485/StyleGan/custom_data_result/00000-stylegan3-t-customdataset-gpus1-batch32-gamma10\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   5000 kimg\n",
            "Dataset path:        ./datasets/customdataset.zip\n",
            "Dataset size:        4729 images\n",
            "Dataset resolution:  128\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "\n",
            "Num images:  9458\n",
            "Image shape: [3, 128, 128]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stylegan3/train.py\", line 286, in <module>\n",
            "    main() # pylint: disable=no-value-for-parameter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/content/stylegan3/train.py\", line 281, in main\n",
            "    launch_training(c=c, desc=desc, outdir=opts.outdir, dry_run=opts.dry_run)\n",
            "  File \"/content/stylegan3/train.py\", line 96, in launch_training\n",
            "    subprocess_fn(rank=0, c=c, temp_dir=temp_dir)\n",
            "  File \"/content/stylegan3/train.py\", line 47, in subprocess_fn\n",
            "    training_loop.training_loop(rank=rank, **c)\n",
            "  File \"/content/stylegan3/training/training_loop.py\", line 152, in training_loop\n",
            "    G = dnnlib.util.construct_class_by_name(**G_kwargs, **common_kwargs).train().requires_grad_(False).to(device) # subclass of torch.nn.Module\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1145, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 820, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1143, in convert\n",
            "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 247, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################\n",
        "#      optional: fine tune a pretrained model\n",
        "#######################################################\n",
        "\n",
        "# you could also fine a StyleGan3: Fine-tune StyleGAN3-R for MetFaces-U using 1 GPU, starting from the pre-trained FFHQ-U pickle.\n",
        "!python train.py --outdir=/content/drive/MyDrive/MDE/SCI6485/StyleGan/custom_data_result --cfg=stylegan3-r --data=./datasets/customdataset.zip  --gpus=1 --batch=32 --batch-gpu=4 --gamma=10.0 --mirror=1 --kimg=5000 --snap=1 \\\n",
        "--resume=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-1024x1024.pkl"
      ],
      "metadata": {
        "id": "oHGoIPUOB-fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQVRH5rr4dki"
      },
      "source": [
        "## Wait an Hour or Two\n",
        "\n",
        "Normal training of a dataset can take days.  For this demonstration, we only want to train for a few hours in order to get familiar with the training process and see the initial results.\n",
        "\n",
        "Results are stored in your Google Drive under your custom path defined above.\n",
        "\n",
        "Each training run is stored in a separate directory.  The initial training run is stored in `00000-customdataset...`.  If you run training twice, the second run will be stored in `00001-customdataset...`.  And so on.\n",
        "\n",
        "Inside the training run directory you will see various files.  `reals.png` shows a sample of the training dataset.  You should see various your custom images in this image. `fakes000000.png` is a sample of generated images from the initial model.  `network-snapshot-XXXXXX.pkl` is the actual model which can be used later to generate \"fake\" images, videos, etc.\n",
        "\n",
        "As training progresses you will see more `fakes` & `network-snapshot` files created.\n",
        "\n",
        "Since we only want to test a training, once you get to around the 500th iteration, you can stop the above training cell.  Then take a look at the `fakes` images and familiarize yourself with how the training progresses.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate images"
      ],
      "metadata": {
        "id": "qGla61GphlVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################\n",
        "#      set the directory where you want to store the new generated images\n",
        "#######################################################\n",
        "\n",
        "# make a directory to store newly generated images\n",
        "!mkdir /content/drive/MyDrive/MDE/SCI6485/StyleGan/generated_images"
      ],
      "metadata": {
        "id": "Lp5q3qWPibOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee10e235-f7ab-4a0b-ff93-79685a557072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/MDE/SCI6485/StyleGan/generated_images’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################\n",
        "#      set --outdir= as the path above\n",
        "#      set --network= as the training result snapshot you want to use for generating the image\n",
        "#######################################################\n",
        "\n",
        "# load the training result and generate a new image\n",
        "# the new images will be stored in the path you created above\n",
        "!python gen_images.py --outdir=/content/drive/MyDrive/MDE/SCI6485/StyleGan/generated_images --trunc=1 --seeds=2 \\\n",
        "    --network=/content/drive/MyDrive/MDE/SCI6485/StyleGan/custom_data/00000-stylegan3-t-customdataset-gpus1-batch32-gamma10/network-snapshot-000012.pkl"
      ],
      "metadata": {
        "id": "qEzvUL9whozG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ae711ef-4cdc-4954-bd84-540994f7b03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"/content/drive/MyDrive/MDE/SCI6485/StyleGan/custom_data/00000-stylegan3-t-pokemondataset-gpus1-batch32-gamma10/network-snapshot-000012.pkl\"...\n",
            "Generating image for seed 2 (0/1) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n"
          ]
        }
      ]
    }
  ]
}